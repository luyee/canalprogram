# Name the components on this agent
LP.sources = r1
LP.channels = c1
LP.sinks = k1

# Describe/configure the source
LP.sources.r1.type = spooldir
LP.sources.r1.spoolDir = /interactive/source_add/LP_files
LP.sources.r1.fileHeader = true
LP.sources.r1.deletePolicy = immediate
LP.sources.r1.recursiveDirectorySearch = true
LP.sources.r1.fileHeaderKey = fileName
LP.sources.r1.ignorePattern=^(.)*\\.tmp$


LP.sinks.k1.type = hdfs
LP.sinks.k1.hdfs.path = hdfs://hadoop1:8020/bigdata/
#LP.sinks.k1.fileType = SequenceFile
#值DataStream表示文件类型，不会被压缩
LP.sinks.k1.hdfs.fileType = DataStream
#针对DataStream，使用Text输出格式
LP.sinks.k1.hdfs.writeFormat = Text
#把原来的文件名作为前缀
LP.sinks.k1.hdfs.rollSize=10485760
LP.sinks.k1.hdfs.rollInterval=0
LP.sinks.k1.hdfs.rollCount=0
LP.sinks.k1.hdfs.idleTimeout=60
LP.sinks.k1.hdfs.callTimeout=100000
LP.sinks.k1.hdfs.filePrefix = %{fileName}

# Use a channel which buffers events in memory
LP.channels.c1.type = file
LP.channels.c1.checkpointDir = /canal/flume/checkpoint/LP
LP.channels.c1.dataDirs = /canal/flume/data/LP

# Bind the source and sink to the channel
LP.sources.r1.channels = c1
LP.sinks.k1.channel = c1
