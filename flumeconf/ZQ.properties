# Name the components on this agent
ZQ.sources = r1
ZQ.channels = c1
ZQ.sinks = k1

# Describe/configure the source
ZQ.sources.r1.type = spooldir
ZQ.sources.r1.spoolDir = /interactive/source_add/ZQ_files
ZQ.sources.r1.fileHeader = true
ZQ.sources.r1.deletePolicy = immediate
ZQ.sources.r1.recursiveDirectorySearch = true
ZQ.sources.r1.fileHeaderKey = fileName
ZQ.sources.r1.ignorePattern=^(.)*\\.tmp$


ZQ.sinks.k1.type = hdfs
ZQ.sinks.k1.hdfs.path = hdfs://hadoop1:8020/bigdata/
#ZQ.sinks.k1.fileType = SequenceFile
#值DataStream表示文件类型，不会被压缩
ZQ.sinks.k1.hdfs.fileType = DataStream
#针对DataStream，使用Text输出格式
ZQ.sinks.k1.hdfs.writeFormat = Text
#把原来的文件名作为前缀
ZQ.sinks.k1.hdfs.rollSize=10485760
ZQ.sinks.k1.hdfs.rollInterval=0
ZQ.sinks.k1.hdfs.rollCount=0
ZQ.sinks.k1.hdfs.idleTimeout=60
ZQ.sinks.k1.hdfs.callTimeout=100000
ZQ.sinks.k1.hdfs.filePrefix = %{fileName}

# Use a channel which buffers events in memory
ZQ.channels.c1.type = file
ZQ.channels.c1.checkpointDir = /canal/flume/checkpoint/ZQ
ZQ.channels.c1.dataDirs = /canal/flume/data/ZQ

# Bind the source and sink to the channel
ZQ.sources.r1.channels = c1
ZQ.sinks.k1.channel = c1
